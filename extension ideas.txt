**- Ability to select *ANY* cartoon character as the reference style image - most achievable
- Select more than one cartoon character as the reference style image - changing the cost/loss function and architecture

Requires re-training the model to add these features

One file: 'instyle_code.npy' is not available on the links they shared -> hopefully this isn't too important

TODO:
add in argument parser to add to second image (user-provided is done, add in the id code - i.e. user can give two ids)
allow the user to to specify the weights of each image
Add in some code to allow the user to specify their own image (I think has to be 1024x1024)

CHECK THE GITHUB ISSUES --> THERE MIGHT BE SOME USEFUL INSIGHTS ON THAT PAGE

#####################################################################################################################################################
TODO: extension ideas 
1) Reference style images being actual human beings -- this requires just retraining on a faces dataset
2) (Facial Warping) Implement a way for basic modifications to the image -- change hair colour, eye size ::: will require changes to latent vector
3) Can specify which expression you want the output character to have -- just basic expressions: happy, sad, neutral, surprised, angry
4) ZERO-SHOT CARTOONIFICATION -- where you specify the style of the images (and don't provide a reference style image)
######################################################################################################################################################


WHY ARE BOTH THE INTRINSIC AND EXTRINSIC STYLE CODES TENSORS OF SHAPE (1, 18, 512)

Idea number 3 - can maybe do in StyleGAN latent space - remember that video about styleGAN where you just change the latent code


TODO: need to figure out how the style is captured from the cartoon image - the extrinsic style code


4, 8, 16, 32, 64, 128, 256, 512, 1024

maybe rewatch the youtube video on how StyleGAN works

train on more generic data - on own dataset - actual human beings
collect more data - anime characters
one model for everything --> not possible with just one model
reference style images could be another person
make images look funnier - 
facial warping
different styles on different sides of the faces
can specify which expression you want the output character to have
actual human faces as the reference style images
zero-shot cartoonification ??  - don't need to provide an actual image -- Not possible because of the architecture of DualStyleGAN