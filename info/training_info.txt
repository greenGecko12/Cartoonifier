All of the things in the ./model directory define the architecture neural networks and the necessary methods
============================================================================================================

The first step in training the model (ignoring prepaing the dataset) is: 
1) Fine-tune StyleGAN. Fine-tune StyleGAN in distributed settings. --> finetune_stylegan.py

I think the pSp encoder finds the closest match in the styleGAN generative space, then puts that noise vector back into styleGAN to get the output
This output is the second image in the 4 image lineup.

This is how pSp works: https://www.youtube.com/watch?v=bfvSwhqsTgM

What is style mixing? The guy said something about style mixing on the fine-level styles.

The pSp encoder uses something called a Feature Pyramid Network, or FPN to extract the styles I think.


The pSp encoder obtains the latent code for the input headshot


I don't think the actual training needs much modification, rather the actual architecture. 
For training, the main thing might be the loss functions.


In generate.py, there's a section where we can MIX the two style codes - this might be the way to go forward